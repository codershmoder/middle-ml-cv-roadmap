{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7795a0b3-707a-49d8-96c3-b02b648532e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c8d5b44-f1f3-4311-a5f4-a62c1384fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVisualOdometry:\n",
    "    def __init__(self, camera_matrix):\n",
    "        self.K = camera_matrix\n",
    "        self.prev_frame = None\n",
    "        self.prev_points = None\n",
    "        # Identity matrix for initial rotation, zero vector for translation\n",
    "        self.cur_R = np.eye(3)\n",
    "        self.cur_t = np.zeros((3, 1))\n",
    "        \n",
    "        # Feature detector (ORB is great for toy examples)\n",
    "        self.detector = cv.FastFeatureDetector_create(threshold=25, nonmaxSuppression=True)\n",
    "\n",
    "    def process_frame(self, frame, frame_id):\n",
    "        # 1. Convert to grayscale\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        if frame_id == 0:\n",
    "            # First frame: just detect points\n",
    "            self.prev_points = self.detector.detect(gray)\n",
    "            self.prev_points = np.array([x.pt for x in self.prev_points], dtype=np.float32)\n",
    "        else:\n",
    "            # 2. Track features from previous frame to current\n",
    "            # Using Lucas-Kanade Optical Flow\n",
    "            curr_points, status, err = cv.calcOpticalFlowPyrLK(self.prev_frame, gray, self.prev_points, None)\n",
    "            \n",
    "            # Filter out points where tracking failed\n",
    "            good_prev = self.prev_points[status.reshape(-1) == 1]\n",
    "            good_curr = curr_points[status.reshape(-1) == 1]\n",
    "\n",
    "            # 3. Estimate Motion (The Core Step)\n",
    "            # Find Essential Matrix using RANSAC\n",
    "            E, mask = cv.findEssentialMat(good_curr, good_prev, self.K, method=cv.RANSAC, prob=0.999, threshold=1.0)\n",
    "            \n",
    "            # 4. Recover Pose (Decompose E into R and t)\n",
    "            _, R, t, mask = cv.recoverPose(E, good_curr, good_prev, self.K)\n",
    "\n",
    "            # 5. Update Trajectory (Simplified: assuming unit scale = 1)\n",
    "            # In real Monocular VO, you need a way to estimate 'absolute_scale'\n",
    "            absolute_scale = 1.0 \n",
    "            self.cur_t = self.cur_t + absolute_scale * self.cur_R.dot(t)\n",
    "            self.cur_R = R.dot(self.cur_R)\n",
    "\n",
    "            # Prepare for next frame\n",
    "            # If tracking points drop too low, re-detect features\n",
    "            if len(good_curr) < 100:\n",
    "                new_points = self.detector.detect(gray)\n",
    "                self.prev_points = np.array([x.pt for x in new_points], dtype=np.float32)\n",
    "            else:\n",
    "                self.prev_points = good_curr.reshape(-1, 2)\n",
    "\n",
    "        self.prev_frame = gray\n",
    "        return self.cur_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7b1c85-0df5-4d5a-bdd4-bb7b120eedd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Camera Matrix (Focal length = 718, Optical Center = 607, 185)\n",
    "K = np.array([[718.8, 0, 607.1],\n",
    "              [0, 718.8, 185.2],\n",
    "              [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c8225ca-fd8a-4c90-ad36-40c30cca2535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0: x=0.00, y=0.00, z=0.00\n",
      "Frame 1: x=0.47, y=-0.03, z=0.88\n",
      "Frame 2: x=0.75, y=-0.37, z=1.78\n",
      "Frame 3: x=0.99, y=-1.34, z=1.78\n",
      "Frame 4: x=1.72, y=-1.21, z=2.44\n",
      "Frame 5: x=2.43, y=-0.56, z=2.73\n",
      "Frame 6: x=2.30, y=-0.51, z=3.72\n",
      "Frame 7: x=2.10, y=-0.57, z=2.74\n",
      "Frame 8: x=2.51, y=-0.93, z=3.58\n",
      "Frame 9: x=3.07, y=-1.55, z=4.12\n",
      "Frame 10: x=2.91, y=-1.14, z=3.22\n",
      "Frame 11: x=3.61, y=-1.75, z=3.59\n",
      "Frame 12: x=4.57, y=-1.82, z=3.32\n",
      "Frame 13: x=4.17, y=-1.16, z=3.96\n",
      "Frame 14: x=4.78, y=-1.82, z=3.51\n",
      "Frame 15: x=5.40, y=-1.23, z=4.04\n",
      "Frame 16: x=5.56, y=-0.42, z=4.60\n",
      "Frame 17: x=5.63, y=-0.34, z=5.59\n",
      "Frame 18: x=6.26, y=0.39, z=5.86\n",
      "Frame 19: x=5.91, y=0.74, z=6.73\n",
      "Frame 20: x=6.81, y=0.72, z=7.17\n",
      "Frame 21: x=7.01, y=0.73, z=6.20\n",
      "Frame 22: x=7.27, y=1.19, z=5.35\n",
      "Frame 23: x=6.97, y=0.94, z=6.27\n",
      "Frame 24: x=6.25, y=1.55, z=5.95\n",
      "Frame 25: x=7.12, y=1.37, z=6.41\n",
      "Frame 26: x=6.32, y=1.59, z=5.85\n",
      "Frame 27: x=5.44, y=1.95, z=6.15\n",
      "Frame 28: x=5.51, y=1.08, z=6.63\n",
      "Frame 29: x=6.07, y=1.87, z=6.89\n",
      "Frame 30: x=5.33, y=2.44, z=6.54\n",
      "Frame 31: x=5.79, y=1.83, z=5.89\n",
      "Frame 32: x=5.94, y=1.27, z=5.07\n",
      "Frame 33: x=5.98, y=0.63, z=4.30\n",
      "Frame 34: x=6.96, y=0.60, z=4.46\n",
      "Frame 35: x=7.67, y=0.07, z=4.00\n",
      "Frame 36: x=8.15, y=0.73, z=4.58\n",
      "Frame 37: x=7.70, y=-0.15, z=4.44\n",
      "Frame 38: x=8.55, y=0.32, z=4.68\n",
      "Frame 39: x=8.88, y=1.25, z=4.84\n",
      "Frame 40: x=8.56, y=0.46, z=4.31\n",
      "Frame 41: x=9.43, y=0.88, z=4.59\n",
      "Frame 42: x=8.62, y=0.32, z=4.40\n",
      "Frame 43: x=7.73, y=-0.11, z=4.26\n",
      "Frame 44: x=8.35, y=0.43, z=4.82\n",
      "Frame 45: x=7.38, y=0.22, z=4.76\n",
      "Frame 46: x=6.98, y=-0.54, z=5.26\n",
      "Frame 47: x=6.09, y=-1.00, z=5.39\n",
      "Frame 48: x=5.20, y=-1.33, z=5.68\n",
      "Frame 49: x=4.23, y=-1.55, z=5.78\n",
      "Frame 50: x=3.40, y=-2.11, z=5.87\n",
      "Frame 51: x=4.25, y=-1.59, z=5.78\n",
      "Frame 52: x=3.35, y=-1.96, z=6.00\n",
      "Frame 53: x=2.48, y=-2.45, z=5.95\n",
      "Frame 54: x=1.66, y=-2.97, z=6.18\n",
      "Frame 55: x=0.85, y=-3.56, z=6.21\n",
      "Frame 56: x=0.04, y=-4.14, z=6.29\n",
      "Frame 57: x=-0.76, y=-4.73, z=6.40\n",
      "Frame 58: x=-1.54, y=-5.33, z=6.57\n",
      "Frame 59: x=-2.20, y=-6.08, z=6.52\n",
      "Frame 60: x=-2.74, y=-6.92, z=6.51\n",
      "Frame 61: x=-3.32, y=-7.74, z=6.53\n",
      "Frame 62: x=-3.65, y=-8.66, z=6.33\n",
      "Frame 63: x=-4.42, y=-9.28, z=6.42\n",
      "Frame 64: x=-3.70, y=-8.60, z=6.51\n",
      "Frame 65: x=-4.33, y=-9.33, z=6.25\n",
      "Frame 66: x=-5.22, y=-9.79, z=6.31\n",
      "Frame 67: x=-5.98, y=-10.43, z=6.33\n",
      "Frame 68: x=-6.84, y=-10.94, z=6.29\n",
      "Frame 69: x=-7.70, y=-11.43, z=6.17\n",
      "Frame 70: x=-8.53, y=-11.99, z=6.06\n",
      "Frame 71: x=-9.32, y=-12.58, z=5.92\n",
      "Frame 72: x=-10.24, y=-12.97, z=5.81\n",
      "Frame 73: x=-11.14, y=-13.38, z=5.67\n",
      "Frame 74: x=-12.05, y=-13.75, z=5.49\n",
      "Frame 75: x=-12.95, y=-14.19, z=5.49\n",
      "Frame 76: x=-13.85, y=-14.61, z=5.42\n",
      "Frame 77: x=-14.73, y=-15.09, z=5.37\n",
      "Frame 78: x=-15.54, y=-15.66, z=5.23\n",
      "Frame 79: x=-16.35, y=-16.24, z=5.17\n",
      "Frame 80: x=-17.25, y=-16.62, z=4.97\n",
      "Frame 81: x=-18.13, y=-17.09, z=4.86\n",
      "Frame 82: x=-18.95, y=-17.64, z=4.71\n",
      "Frame 83: x=-19.66, y=-18.30, z=4.45\n",
      "Frame 84: x=-20.36, y=-18.97, z=4.23\n",
      "Frame 85: x=-21.11, y=-19.61, z=4.05\n",
      "Frame 86: x=-21.94, y=-20.16, z=3.95\n",
      "Frame 87: x=-21.17, y=-19.56, z=4.18\n",
      "Frame 88: x=-22.03, y=-20.06, z=4.06\n",
      "Frame 89: x=-22.82, y=-20.67, z=4.01\n",
      "Frame 90: x=-23.72, y=-21.11, z=4.00\n",
      "Frame 91: x=-24.64, y=-21.51, z=4.02\n",
      "Frame 92: x=-25.56, y=-21.89, z=4.10\n",
      "Frame 93: x=-26.36, y=-22.50, z=4.14\n",
      "Frame 94: x=-27.25, y=-22.94, z=4.15\n",
      "Frame 95: x=-28.14, y=-23.39, z=4.22\n",
      "Frame 96: x=-29.10, y=-23.57, z=4.44\n",
      "Frame 97: x=-30.01, y=-23.98, z=4.54\n",
      "Frame 98: x=-30.92, y=-24.36, z=4.66\n",
      "Frame 99: x=-31.88, y=-24.57, z=4.88\n",
      "Frame 100: x=-32.81, y=-24.91, z=4.99\n",
      "Frame 101: x=-33.71, y=-25.24, z=5.27\n",
      "Frame 102: x=-34.54, y=-25.68, z=5.62\n",
      "Frame 103: x=-35.34, y=-26.24, z=5.84\n",
      "Frame 104: x=-34.50, y=-25.77, z=5.56\n",
      "Frame 105: x=-35.27, y=-26.39, z=5.72\n",
      "Frame 106: x=-36.01, y=-27.02, z=5.95\n",
      "Frame 107: x=-36.69, y=-27.73, z=6.12\n",
      "Frame 108: x=-37.47, y=-28.34, z=6.29\n",
      "Frame 109: x=-38.23, y=-28.97, z=6.45\n",
      "Frame 110: x=-39.02, y=-29.54, z=6.66\n",
      "Frame 111: x=-39.62, y=-30.31, z=6.87\n",
      "Frame 112: x=-40.39, y=-30.94, z=6.96\n",
      "Frame 113: x=-41.17, y=-31.53, z=7.18\n",
      "Frame 114: x=-41.23, y=-32.49, z=7.46\n",
      "Frame 115: x=-40.40, y=-32.01, z=7.16\n",
      "Frame 116: x=-41.21, y=-32.49, z=7.49\n",
      "Frame 117: x=-42.05, y=-32.83, z=7.93\n",
      "Frame 118: x=-41.93, y=-33.19, z=8.86\n",
      "Frame 119: x=-42.82, y=-33.52, z=9.18\n",
      "Frame 120: x=-43.48, y=-34.15, z=9.59\n",
      "Frame 121: x=-44.34, y=-34.60, z=9.83\n",
      "Frame 122: x=-44.85, y=-34.34, z=10.65\n",
      "Frame 123: x=-45.69, y=-34.76, z=10.99\n",
      "Frame 124: x=-46.22, y=-34.88, z=11.83\n",
      "Frame 125: x=-47.07, y=-35.33, z=12.11\n",
      "Frame 126: x=-47.35, y=-35.80, z=12.95\n",
      "Frame 127: x=-47.58, y=-35.96, z=13.91\n",
      "Frame 128: x=-47.76, y=-36.12, z=14.88\n",
      "Frame 129: x=-48.58, y=-36.58, z=15.23\n",
      "Frame 130: x=-49.16, y=-36.01, z=15.80\n",
      "Frame 131: x=-49.93, y=-36.65, z=15.71\n",
      "Frame 132: x=-50.42, y=-35.81, z=15.95\n"
     ]
    }
   ],
   "source": [
    "vo = SimpleVisualOdometry(K)\n",
    "cap = cv.VideoCapture(r'D:\\Python things\\middle-ml-cv-roadmap\\data\\raw\\video_2025-12-16_03-45-11.mp4')\n",
    "\n",
    "frame_id = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    pos = vo.process_frame(frame, frame_id)\n",
    "    print(f\"Frame {frame_id}: x={pos[0][0]:.2f}, y={pos[1][0]:.2f}, z={pos[2][0]:.2f}\")\n",
    "    \n",
    "    frame_id += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-ml",
   "language": "python",
   "name": "cv-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
