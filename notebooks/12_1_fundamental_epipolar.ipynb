{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd61bf62-c634-4fc6-b569-e7727c69bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d74cb6-b51c-4201-b503-18d4fc2755cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Draw epipolar lines in img2 corresponding to pts1 in img1, and vice versa.\n",
    "\"\"\"\n",
    "def draw_epilines(img1, img2, pts1, pts2, F):    \n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "\n",
    "    # Compute epilines in img2 for points in img1: l2 = F * x1\n",
    "    lines2 = cv.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F).reshape(-1, 3)\n",
    "    img2_lines = img2.copy()\n",
    "\n",
    "    for (a, b, c), p2 in zip(lines2, pts2):\n",
    "        # line: a*x + b*y + c = 0\n",
    "        x0, y0 = 0, int(-c / b) if abs(b) > 1e-9 else 0\n",
    "        x1, y1 = w2, int(-(c + a * w2) / b) if abs(b) > 1e-9 else h2\n",
    "        cv.line(img2_lines, (x0, y0), (x1, y1), (0, 255, 0), 1)\n",
    "        cv.circle(img2_lines, tuple(p2.astype(int)), 4, (0, 0, 255), -1)\n",
    "\n",
    "    # Compute epilines in img1 for points in img2: l1 = F^T * x2\n",
    "    lines1 = cv.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F).reshape(-1, 3)\n",
    "    img1_lines = img1.copy()\n",
    "\n",
    "    for (a, b, c), p1 in zip(lines1, pts1):\n",
    "        x0, y0 = 0, int(-c / b) if abs(b) > 1e-9 else 0\n",
    "        x1, y1 = w1, int(-(c + a * w1) / b) if abs(b) > 1e-9 else h1\n",
    "        cv.line(img1_lines, (x0, y0), (x1, y1), (0, 255, 0), 1)\n",
    "        cv.circle(img1_lines, tuple(p1.astype(int)), 4, (0, 0, 255), -1)\n",
    "\n",
    "    return img1_lines, img2_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971cd47a-7c3b-416a-9423-a5e170d99c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(img_path1, img_path2, max_vis=30):\n",
    "    img1 = cv.imread(img_path1)\n",
    "    img2 = cv.imread(img_path2)\n",
    "    if img1 is None or img2 is None:\n",
    "        raise FileNotFoundError(\"Could not read one of the images.\")\n",
    "\n",
    "    gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)\n",
    "    gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # ORB features (fast, free)\n",
    "    orb = cv.ORB_create(nfeatures=4000)\n",
    "    k1, d1 = orb.detectAndCompute(gray1, None)\n",
    "    k2, d2 = orb.detectAndCompute(gray2, None)\n",
    "\n",
    "    if d1 is None or d2 is None:\n",
    "        raise RuntimeError(\"No descriptors found. Try different images.\")\n",
    "\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=False)\n",
    "    matches = bf.knnMatch(d1, d2, k=2)\n",
    "\n",
    "    # Lowe ratio test\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good) < 12:\n",
    "        raise RuntimeError(f\"Not enough good matches ({len(good)}). Try more textured images.\")\n",
    "\n",
    "    pts1 = np.float32([k1[m.queryIdx].pt for m in good])\n",
    "    pts2 = np.float32([k2[m.trainIdx].pt for m in good])\n",
    "\n",
    "    # Robust F with RANSAC\n",
    "    F, mask = cv.findFundamentalMat(pts1, pts2, method=cv.FM_RANSAC, ransacReprojThreshold=1.0, confidence=0.99)\n",
    "    if F is None:\n",
    "        raise RuntimeError(\"Fundamental matrix estimation failed.\")\n",
    "\n",
    "    inliers1 = pts1[mask.ravel() == 1]\n",
    "    inliers2 = pts2[mask.ravel() == 1]\n",
    "    print(f\"Good matches: {len(good)} | Inliers: {len(inliers1)}\")\n",
    "    print(\"F:\\n\", F)\n",
    "\n",
    "    # Visualize a subset of inlier correspondences with epipolar lines\n",
    "    n = min(max_vis, len(inliers1))\n",
    "    idx = np.random.choice(len(inliers1), n, replace=False)\n",
    "    vis1, vis2 = draw_epilines(img1, img2, inliers1[idx], inliers2[idx], F)\n",
    "\n",
    "    cv.imshow(\"Image 1 - epilines from Image 2 points\", vis1)\n",
    "    cv.imshow(\"Image 2 - epilines from Image 1 points\", vis2)\n",
    "\n",
    "    # Also show matched features (inliers only)\n",
    "    inlier_matches = [m for m, keep in zip(good, mask.ravel()) if keep]\n",
    "    match_vis = cv.drawMatches(img1, k1, img2, k2, inlier_matches[:200], None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv.imshow(\"Inlier matches (first 200)\", match_vis)\n",
    "\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68c5eaa-9de5-444c-9593-122de593d783",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = r'D:\\Python things\\middle-ml-cv-roadmap\\data\\raw'\n",
    "img_1 = 'img_example_11.jpg'\n",
    "img_2 = 'img_example_12.jpg'\n",
    "img_1_path = os.path.join(img_dir, img_1)\n",
    "img_2_path = os.path.join(img_dir, img_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5099696-844f-43a7-a751-acda4721c04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good matches: 298 | Inliers: 123\n",
      "F:\n",
      " [[-2.85667211e-06 -2.17996468e-05  1.61207538e-02]\n",
      " [ 3.04923486e-05 -4.35045063e-07 -3.60593117e-02]\n",
      " [-1.74560433e-02  3.39166362e-02  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "main(img_1_path, img_2_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-ml",
   "language": "python",
   "name": "cv-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
